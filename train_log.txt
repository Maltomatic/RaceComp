Training on GPU ID: 0, NVIDIA GeForce RTX 4070 Laptop GPU

=== Training with minority: All ===

--- Epoch 1 ---
Batch 001 | train: loss 0.9446  PSNR 12.29  SSIM 0.0268
Batch 301 | train: loss 0.7176  PSNR 13.89  SSIM 0.4437
Batch 601 | train: loss 0.6238  PSNR 15.03  SSIM 0.5747
Batch 901 | train: loss 0.5592  PSNR 15.91  SSIM 0.6453
Batch 1201 | train: loss 0.5066  PSNR 16.76  SSIM 0.6950
Batch 1501 | train: loss 0.4610  PSNR 17.62  SSIM 0.7328
Batch 1801 | train: loss 0.4210  PSNR 18.45  SSIM 0.7624
Batch 2101 | train: loss 0.3894  PSNR 19.13  SSIM 0.7855
Batch 2401 | train: loss 0.3644  PSNR 19.71  SSIM 0.8039
Batch 2701 | train: loss 0.3438  PSNR 20.19  SSIM 0.8187
Batch 3001 | train: loss 0.3268  PSNR 20.61  SSIM 0.8310
Batch 3301 | train: loss 0.3124  PSNR 20.97  SSIM 0.8413
Batch 3601 | train: loss 0.2997  PSNR 21.30  SSIM 0.8503
Batch 3901 | train: loss 0.2890  PSNR 21.59  SSIM 0.8580
Batch 4201 | train: loss 0.2792  PSNR 21.87  SSIM 0.8648
Batch 4501 | train: loss 0.2703  PSNR 22.12  SSIM 0.8709
Batch 4801 | train: loss 0.2624  PSNR 22.35  SSIM 0.8763
Batch 5101 | train: loss 0.2553  PSNR 22.56  SSIM 0.8812
Batch 5401 | train: loss 0.2489  PSNR 22.76  SSIM 0.8856
Batch 5701 | train: loss 0.2431  PSNR 22.94  SSIM 0.8896
Batch 6001 | train: loss 0.2377  PSNR 23.11  SSIM 0.8933
Batch 6301 | train: loss 0.2327  PSNR 23.27  SSIM 0.8966
Batch 6601 | train: loss 0.2281  PSNR 23.42  SSIM 0.8997
Batch 6901 | train: loss 0.2237  PSNR 23.57  SSIM 0.9025
Batch 7201 | train: loss 0.2197  PSNR 23.70  SSIM 0.9052
Batch 7501 | train: loss 0.2159  PSNR 23.83  SSIM 0.9076
Batch 7801 | train: loss 0.2125  PSNR 23.95  SSIM 0.9099
Batch 8101 | train: loss 0.2092  PSNR 24.06  SSIM 0.9120
Epoch 001 | train: loss 0.2088  PSNR 24.08  SSIM 0.9123
==Validation:==
per-race (val): East Asian: SSIM 0.970, PSNR 27.53  White: SSIM 0.969, PSNR 27.51  Latino_Hispanic: SSIM 0.970, PSNR 27.48  Southeast Asian: SSIM 0.969, PSNR 27.48  Black: SSIM 0.969, PSNR 27.54  Indian: SSIM 0.970, PSNR 27.53  Middle Eastern: SSIM 0.970, PSNR 27.52
--- Epoch 2 ---
Batch 001 | train: loss 0.1247  PSNR 26.98  SSIM 0.9703
Batch 301 | train: loss 0.1209  PSNR 27.15  SSIM 0.9682
Batch 601 | train: loss 0.1193  PSNR 27.23  SSIM 0.9686
Batch 901 | train: loss 0.1179  PSNR 27.29  SSIM 0.9689
Batch 1201 | train: loss 0.1172  PSNR 27.32  SSIM 0.9691
Batch 1501 | train: loss 0.1165  PSNR 27.35  SSIM 0.9692
Batch 1801 | train: loss 0.1160  PSNR 27.39  SSIM 0.9694
Batch 2101 | train: loss 0.1153  PSNR 27.42  SSIM 0.9696
Batch 2401 | train: loss 0.1147  PSNR 27.44  SSIM 0.9697
Batch 2701 | train: loss 0.1138  PSNR 27.48  SSIM 0.9699
Batch 3001 | train: loss 0.1133  PSNR 27.51  SSIM 0.9700
Batch 3301 | train: loss 0.1126  PSNR 27.54  SSIM 0.9701
Batch 3601 | train: loss 0.1119  PSNR 27.56  SSIM 0.9703
Batch 3901 | train: loss 0.1112  PSNR 27.59  SSIM 0.9704
Batch 4201 | train: loss 0.1107  PSNR 27.61  SSIM 0.9705
Batch 4501 | train: loss 0.1102  PSNR 27.63  SSIM 0.9706
Batch 4801 | train: loss 0.1096  PSNR 27.65  SSIM 0.9707
Batch 5101 | train: loss 0.1092  PSNR 27.67  SSIM 0.9707
Batch 5401 | train: loss 0.1088  PSNR 27.69  SSIM 0.9708
Batch 5701 | train: loss 0.1084  PSNR 27.70  SSIM 0.9709
Batch 6001 | train: loss 0.1080  PSNR 27.72  SSIM 0.9709
Batch 6301 | train: loss 0.1077  PSNR 27.73  SSIM 0.9710
Batch 6601 | train: loss 0.1073  PSNR 27.75  SSIM 0.9710
Batch 6901 | train: loss 0.1070  PSNR 27.76  SSIM 0.9710
Batch 7201 | train: loss 0.1067  PSNR 27.77  SSIM 0.9711
Batch 7501 | train: loss 0.1064  PSNR 27.78  SSIM 0.9711
Batch 7801 | train: loss 0.1061  PSNR 27.79  SSIM 0.9712
Batch 8101 | train: loss 0.1059  PSNR 27.80  SSIM 0.9712
Epoch 002 | train: loss 0.1059  PSNR 27.80  SSIM 0.9712
==Validation:==
per-race (val): East Asian: SSIM 0.973, PSNR 28.23  White: SSIM 0.972, PSNR 28.20  Latino_Hispanic: SSIM 0.973, PSNR 28.18  Southeast Asian: SSIM 0.972, PSNR 28.17  Black: SSIM 0.972, PSNR 28.24  Indian: SSIM 0.972, PSNR 28.23  Middle Eastern: SSIM 0.972, PSNR 28.22
--- Epoch 3 ---
Batch 001 | train: loss 0.0958  PSNR 27.99  SSIM 0.9690
Batch 301 | train: loss 0.1124  PSNR 27.71  SSIM 0.9714
Batch 601 | train: loss 0.1120  PSNR 27.74  SSIM 0.9717
Batch 901 | train: loss 0.1102  PSNR 27.82  SSIM 0.9719
Batch 1201 | train: loss 0.1098  PSNR 27.85  SSIM 0.9722
Batch 1501 | train: loss 0.1088  PSNR 27.90  SSIM 0.9724
Batch 1801 | train: loss 0.1081  PSNR 27.94  SSIM 0.9726
Batch 2101 | train: loss 0.1075  PSNR 27.97  SSIM 0.9728
Batch 2401 | train: loss 0.1069  PSNR 28.01  SSIM 0.9730
Batch 2701 | train: loss 0.1065  PSNR 28.03  SSIM 0.9732
Batch 3001 | train: loss 0.1062  PSNR 28.06  SSIM 0.9733
Batch 3301 | train: loss 0.1056  PSNR 28.09  SSIM 0.9735
Batch 3601 | train: loss 0.1049  PSNR 28.13  SSIM 0.9737
Batch 3901 | train: loss 0.1043  PSNR 28.16  SSIM 0.9738
Batch 4201 | train: loss 0.1038  PSNR 28.19  SSIM 0.9739
Batch 4501 | train: loss 0.1033  PSNR 28.22  SSIM 0.9741
Batch 4801 | train: loss 0.1028  PSNR 28.25  SSIM 0.9742
Batch 5101 | train: loss 0.1023  PSNR 28.28  SSIM 0.9743
Batch 5401 | train: loss 0.1017  PSNR 28.31  SSIM 0.9745
Batch 5701 | train: loss 0.1011  PSNR 28.34  SSIM 0.9746
Batch 6001 | train: loss 0.1006  PSNR 28.37  SSIM 0.9747
Batch 6301 | train: loss 0.1002  PSNR 28.39  SSIM 0.9748
